{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet\n",
    "이 노트북은 AlexNet을 구현하는 노트북이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 0us/step\n",
      "x_train shape:  (40000, 32, 32, 3)\n",
      "y_train shape:  (40000, 1)\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 불러오기\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# 이름 설정하기\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# 데이터 split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# 결과 확인\n",
    "print(\"x_train shape: \", x_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ds:  <_TensorSliceDataset element_spec=(TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name=None), TensorSpec(shape=(1,), dtype=tf.uint8, name=None))>\n",
      "test_ds:  <_TensorSliceDataset element_spec=(TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name=None), TensorSpec(shape=(1,), dtype=tf.uint8, name=None))>\n",
      "val_ds:  <_TensorSliceDataset element_spec=(TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name=None), TensorSpec(shape=(1,), dtype=tf.uint8, name=None))>\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "\n",
    "print(\"train_ds: \", train_ds)\n",
    "print(\"test_ds: \", test_ds)\n",
    "print(\"val_ds: \", val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(image, label):\n",
    "\n",
    "    # Resize images form 32*32 to 227*227\n",
    "    image = tf.image.resize(image, (227, 227))\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(128, drop_remainder=True)\n",
    "test_ds = test_ds.batch(128, drop_remainder=True)\n",
    "val_ds = val_ds.batch(128, drop_remainder=True)\n",
    "\n",
    "train_ds = train_ds.map(process_images)\n",
    "test_ds = test_ds.map(process_images)\n",
    "val_ds = val_ds.map(process_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, MaxPool2D\n",
    "\n",
    "class AlexNet(Sequential):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.add(Conv2D(96, kernel_size=11, strides=4, activation='relu', input_shape=(227, 227, 3)))\n",
    "        self.add(BatchNormalization())\n",
    "        self.add(MaxPool2D(3, 2))\n",
    "\n",
    "        self.add(Conv2D(256, kernel_size=5, strides=1, activation='relu', padding='same'))\n",
    "        self.add(BatchNormalization())\n",
    "        self.add(MaxPool2D(3, 2))\n",
    "\n",
    "        self.add(Conv2D(384, kernel_size=3, strides=1, activation='relu', padding='same'))\n",
    "        self.add(BatchNormalization())\n",
    "\n",
    "        self.add(Conv2D(384, kernel_size=3, strides=1, activation='relu', padding='same'))\n",
    "        self.add(BatchNormalization())\n",
    "\n",
    "        self.add(Conv2D(256, kernel_size=3, strides=1, activation='relu', padding='same'))\n",
    "        self.add(BatchNormalization())\n",
    "        self.add(MaxPool2D(3, 2))\n",
    "\n",
    "        self.add(Flatten())\n",
    "        self.add(Dense(4096, activation='relu'))\n",
    "        self.add(Dropout(0.5))\n",
    "        self.add(Dense(4096, activation='relu'))\n",
    "        self.add(Dropout(0.5))\n",
    "        self.add(Dense(10, activation='softmax'))\n",
    "\n",
    "        self.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jkwor\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"alex_net\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"alex_net\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">34,944</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">614,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">885,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,327,488</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">884,992</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9216</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">37,752,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">16,781,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">40,970</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │        \u001b[38;5;34m34,944\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │           \u001b[38;5;34m384\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m614,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │       \u001b[38;5;34m885,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │         \u001b[38;5;34m1,536\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │     \u001b[38;5;34m1,327,488\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │         \u001b[38;5;34m1,536\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m884,992\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9216\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │    \u001b[38;5;34m37,752,832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │    \u001b[38;5;34m16,781,312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m40,970\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">58,327,818</span> (222.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m58,327,818\u001b[0m (222.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">58,325,066</span> (222.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m58,325,066\u001b[0m (222.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,752</span> (10.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,752\u001b[0m (10.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AlexNet()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m737s\u001b[0m 2s/step - accuracy: 0.7253 - loss: 0.8201 - val_accuracy: 0.6965 - val_loss: 0.9090\n",
      "Epoch 2/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m736s\u001b[0m 2s/step - accuracy: 0.7501 - loss: 0.7497 - val_accuracy: 0.7355 - val_loss: 0.7996\n",
      "Epoch 3/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m735s\u001b[0m 2s/step - accuracy: 0.7687 - loss: 0.6866 - val_accuracy: 0.7121 - val_loss: 0.8638\n",
      "Epoch 4/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m736s\u001b[0m 2s/step - accuracy: 0.7894 - loss: 0.6239 - val_accuracy: 0.6926 - val_loss: 0.9336\n",
      "Epoch 5/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m738s\u001b[0m 2s/step - accuracy: 0.8076 - loss: 0.5731 - val_accuracy: 0.7588 - val_loss: 0.7339\n",
      "Epoch 6/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m739s\u001b[0m 2s/step - accuracy: 0.8284 - loss: 0.5259 - val_accuracy: 0.7464 - val_loss: 0.7936\n",
      "Epoch 7/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m741s\u001b[0m 2s/step - accuracy: 0.8425 - loss: 0.4757 - val_accuracy: 0.7428 - val_loss: 0.8181\n",
      "Epoch 8/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m739s\u001b[0m 2s/step - accuracy: 0.8543 - loss: 0.4502 - val_accuracy: 0.7546 - val_loss: 0.8020\n",
      "Epoch 9/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m740s\u001b[0m 2s/step - accuracy: 0.8718 - loss: 0.3973 - val_accuracy: 0.7626 - val_loss: 0.7697\n",
      "Epoch 10/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m740s\u001b[0m 2s/step - accuracy: 0.8806 - loss: 0.3639 - val_accuracy: 0.7865 - val_loss: 0.6984\n",
      "Epoch 11/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m740s\u001b[0m 2s/step - accuracy: 0.8903 - loss: 0.3474 - val_accuracy: 0.7712 - val_loss: 0.7595\n",
      "Epoch 12/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m739s\u001b[0m 2s/step - accuracy: 0.9045 - loss: 0.2989 - val_accuracy: 0.7684 - val_loss: 0.7736\n",
      "Epoch 13/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m739s\u001b[0m 2s/step - accuracy: 0.9124 - loss: 0.2718 - val_accuracy: 0.7663 - val_loss: 0.8085\n",
      "Epoch 14/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m739s\u001b[0m 2s/step - accuracy: 0.9207 - loss: 0.2554 - val_accuracy: 0.8066 - val_loss: 0.6982\n",
      "Epoch 15/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m739s\u001b[0m 2s/step - accuracy: 0.9259 - loss: 0.2400 - val_accuracy: 0.7870 - val_loss: 0.7752\n",
      "Epoch 16/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m740s\u001b[0m 2s/step - accuracy: 0.9280 - loss: 0.2272 - val_accuracy: 0.8094 - val_loss: 0.7448\n",
      "Epoch 17/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m741s\u001b[0m 2s/step - accuracy: 0.9398 - loss: 0.2018 - val_accuracy: 0.8095 - val_loss: 0.7504\n",
      "Epoch 18/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m740s\u001b[0m 2s/step - accuracy: 0.9443 - loss: 0.1857 - val_accuracy: 0.8073 - val_loss: 0.7808\n",
      "Epoch 19/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m741s\u001b[0m 2s/step - accuracy: 0.9470 - loss: 0.1877 - val_accuracy: 0.7104 - val_loss: 1.1169\n",
      "Epoch 20/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m740s\u001b[0m 2s/step - accuracy: 0.9455 - loss: 0.1815 - val_accuracy: 0.8113 - val_loss: 0.8065\n",
      "Epoch 21/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m741s\u001b[0m 2s/step - accuracy: 0.9535 - loss: 0.1605 - val_accuracy: 0.8068 - val_loss: 0.8366\n",
      "Epoch 22/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m742s\u001b[0m 2s/step - accuracy: 0.9565 - loss: 0.1567 - val_accuracy: 0.8206 - val_loss: 0.7522\n",
      "Epoch 23/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m740s\u001b[0m 2s/step - accuracy: 0.9577 - loss: 0.1442 - val_accuracy: 0.8156 - val_loss: 0.8124\n",
      "Epoch 24/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m743s\u001b[0m 2s/step - accuracy: 0.9580 - loss: 0.1533 - val_accuracy: 0.8108 - val_loss: 0.7996\n",
      "Epoch 25/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m742s\u001b[0m 2s/step - accuracy: 0.9622 - loss: 0.1349 - val_accuracy: 0.8177 - val_loss: 0.8127\n",
      "Epoch 26/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m741s\u001b[0m 2s/step - accuracy: 0.9647 - loss: 0.1223 - val_accuracy: 0.8063 - val_loss: 0.8657\n",
      "Epoch 27/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m741s\u001b[0m 2s/step - accuracy: 0.9665 - loss: 0.1177 - val_accuracy: 0.8128 - val_loss: 0.9281\n",
      "Epoch 28/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m741s\u001b[0m 2s/step - accuracy: 0.9673 - loss: 0.1157 - val_accuracy: 0.8151 - val_loss: 0.8172\n",
      "Epoch 29/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m742s\u001b[0m 2s/step - accuracy: 0.9681 - loss: 0.1126 - val_accuracy: 0.7751 - val_loss: 1.1335\n",
      "Epoch 30/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m740s\u001b[0m 2s/step - accuracy: 0.9728 - loss: 0.1069 - val_accuracy: 0.8273 - val_loss: 0.8600\n",
      "Epoch 31/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m741s\u001b[0m 2s/step - accuracy: 0.9715 - loss: 0.1053 - val_accuracy: 0.8017 - val_loss: 0.8824\n",
      "Epoch 32/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m740s\u001b[0m 2s/step - accuracy: 0.9698 - loss: 0.1088 - val_accuracy: 0.8064 - val_loss: 0.7956\n",
      "Epoch 33/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m742s\u001b[0m 2s/step - accuracy: 0.9774 - loss: 0.0838 - val_accuracy: 0.8177 - val_loss: 0.9726\n",
      "Epoch 34/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m689s\u001b[0m 2s/step - accuracy: 0.9779 - loss: 0.0816 - val_accuracy: 0.8200 - val_loss: 0.7893\n",
      "Epoch 35/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m643s\u001b[0m 2s/step - accuracy: 0.9757 - loss: 0.0894 - val_accuracy: 0.8087 - val_loss: 0.9282\n",
      "Epoch 36/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m643s\u001b[0m 2s/step - accuracy: 0.9749 - loss: 0.0966 - val_accuracy: 0.8099 - val_loss: 0.9860\n",
      "Epoch 37/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m643s\u001b[0m 2s/step - accuracy: 0.9781 - loss: 0.0848 - val_accuracy: 0.8084 - val_loss: 0.9968\n",
      "Epoch 38/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m644s\u001b[0m 2s/step - accuracy: 0.9782 - loss: 0.0823 - val_accuracy: 0.7929 - val_loss: 1.1607\n",
      "Epoch 39/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m643s\u001b[0m 2s/step - accuracy: 0.9804 - loss: 0.0757 - val_accuracy: 0.8105 - val_loss: 0.9250\n",
      "Epoch 40/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m643s\u001b[0m 2s/step - accuracy: 0.9797 - loss: 0.0771 - val_accuracy: 0.8161 - val_loss: 1.0233\n",
      "Epoch 41/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m644s\u001b[0m 2s/step - accuracy: 0.9816 - loss: 0.0691 - val_accuracy: 0.8184 - val_loss: 0.9825\n",
      "Epoch 42/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m645s\u001b[0m 2s/step - accuracy: 0.9801 - loss: 0.0729 - val_accuracy: 0.8105 - val_loss: 0.8790\n",
      "Epoch 43/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m645s\u001b[0m 2s/step - accuracy: 0.9821 - loss: 0.0633 - val_accuracy: 0.8083 - val_loss: 0.8249\n",
      "Epoch 44/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m646s\u001b[0m 2s/step - accuracy: 0.9804 - loss: 0.0746 - val_accuracy: 0.7833 - val_loss: 1.2949\n",
      "Epoch 45/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m648s\u001b[0m 2s/step - accuracy: 0.9815 - loss: 0.0691 - val_accuracy: 0.8167 - val_loss: 1.0505\n",
      "Epoch 46/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m645s\u001b[0m 2s/step - accuracy: 0.9814 - loss: 0.0751 - val_accuracy: 0.8105 - val_loss: 0.9681\n",
      "Epoch 47/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m645s\u001b[0m 2s/step - accuracy: 0.9835 - loss: 0.0628 - val_accuracy: 0.8143 - val_loss: 0.9334\n",
      "Epoch 48/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m646s\u001b[0m 2s/step - accuracy: 0.9860 - loss: 0.0492 - val_accuracy: 0.8093 - val_loss: 1.0134\n",
      "Epoch 49/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m648s\u001b[0m 2s/step - accuracy: 0.9812 - loss: 0.0715 - val_accuracy: 0.8239 - val_loss: 1.0122\n",
      "Epoch 50/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m648s\u001b[0m 2s/step - accuracy: 0.9864 - loss: 0.0497 - val_accuracy: 0.8080 - val_loss: 0.9828\n",
      "Epoch 51/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m649s\u001b[0m 2s/step - accuracy: 0.9828 - loss: 0.0654 - val_accuracy: 0.8334 - val_loss: 1.0647\n",
      "Epoch 52/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m647s\u001b[0m 2s/step - accuracy: 0.9846 - loss: 0.0593 - val_accuracy: 0.7793 - val_loss: 1.3461\n",
      "Epoch 53/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m646s\u001b[0m 2s/step - accuracy: 0.9836 - loss: 0.0648 - val_accuracy: 0.8233 - val_loss: 1.0054\n",
      "Epoch 54/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m648s\u001b[0m 2s/step - accuracy: 0.9853 - loss: 0.0548 - val_accuracy: 0.8229 - val_loss: 0.9306\n",
      "Epoch 55/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m647s\u001b[0m 2s/step - accuracy: 0.9851 - loss: 0.0556 - val_accuracy: 0.8186 - val_loss: 1.0213\n",
      "Epoch 56/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m649s\u001b[0m 2s/step - accuracy: 0.9836 - loss: 0.0648 - val_accuracy: 0.8116 - val_loss: 0.9025\n",
      "Epoch 57/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m648s\u001b[0m 2s/step - accuracy: 0.9857 - loss: 0.0582 - val_accuracy: 0.8272 - val_loss: 1.3147\n",
      "Epoch 58/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m648s\u001b[0m 2s/step - accuracy: 0.9844 - loss: 0.0682 - val_accuracy: 0.8204 - val_loss: 1.1564\n",
      "Epoch 59/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m648s\u001b[0m 2s/step - accuracy: 0.9857 - loss: 0.0601 - val_accuracy: 0.8234 - val_loss: 0.8687\n",
      "Epoch 60/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m648s\u001b[0m 2s/step - accuracy: 0.9830 - loss: 0.0634 - val_accuracy: 0.7886 - val_loss: 1.0133\n",
      "Epoch 61/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m648s\u001b[0m 2s/step - accuracy: 0.9864 - loss: 0.0527 - val_accuracy: 0.8332 - val_loss: 1.2214\n",
      "Epoch 62/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m649s\u001b[0m 2s/step - accuracy: 0.9887 - loss: 0.0515 - val_accuracy: 0.8117 - val_loss: 0.8946\n",
      "Epoch 63/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m649s\u001b[0m 2s/step - accuracy: 0.9859 - loss: 0.0529 - val_accuracy: 0.8240 - val_loss: 1.0289\n",
      "Epoch 64/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m650s\u001b[0m 2s/step - accuracy: 0.9884 - loss: 0.0442 - val_accuracy: 0.8189 - val_loss: 1.1430\n",
      "Epoch 65/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m648s\u001b[0m 2s/step - accuracy: 0.9869 - loss: 0.0515 - val_accuracy: 0.8013 - val_loss: 1.2203\n",
      "Epoch 66/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m649s\u001b[0m 2s/step - accuracy: 0.9877 - loss: 0.0481 - val_accuracy: 0.8092 - val_loss: 1.1865\n",
      "Epoch 67/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m649s\u001b[0m 2s/step - accuracy: 0.9849 - loss: 0.0623 - val_accuracy: 0.8305 - val_loss: 0.9237\n",
      "Epoch 68/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m650s\u001b[0m 2s/step - accuracy: 0.9880 - loss: 0.0476 - val_accuracy: 0.8227 - val_loss: 1.2591\n",
      "Epoch 69/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m651s\u001b[0m 2s/step - accuracy: 0.9911 - loss: 0.0357 - val_accuracy: 0.8275 - val_loss: 1.0134\n",
      "Epoch 70/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m651s\u001b[0m 2s/step - accuracy: 0.9881 - loss: 0.0473 - val_accuracy: 0.8123 - val_loss: 1.1577\n",
      "Epoch 71/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m651s\u001b[0m 2s/step - accuracy: 0.9872 - loss: 0.0552 - val_accuracy: 0.8301 - val_loss: 1.2577\n",
      "Epoch 72/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m652s\u001b[0m 2s/step - accuracy: 0.9860 - loss: 0.0554 - val_accuracy: 0.8336 - val_loss: 1.2846\n",
      "Epoch 73/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m652s\u001b[0m 2s/step - accuracy: 0.9885 - loss: 0.0468 - val_accuracy: 0.7963 - val_loss: 1.3824\n",
      "Epoch 74/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m650s\u001b[0m 2s/step - accuracy: 0.9875 - loss: 0.0539 - val_accuracy: 0.8308 - val_loss: 1.1912\n",
      "Epoch 75/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m652s\u001b[0m 2s/step - accuracy: 0.9882 - loss: 0.0458 - val_accuracy: 0.8301 - val_loss: 1.0832\n",
      "Epoch 76/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m651s\u001b[0m 2s/step - accuracy: 0.9887 - loss: 0.0520 - val_accuracy: 0.8090 - val_loss: 1.1609\n",
      "Epoch 77/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m651s\u001b[0m 2s/step - accuracy: 0.9868 - loss: 0.0532 - val_accuracy: 0.8357 - val_loss: 1.0572\n",
      "Epoch 78/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m653s\u001b[0m 2s/step - accuracy: 0.9900 - loss: 0.0429 - val_accuracy: 0.8396 - val_loss: 1.1529\n",
      "Epoch 79/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m651s\u001b[0m 2s/step - accuracy: 0.9909 - loss: 0.0379 - val_accuracy: 0.8249 - val_loss: 1.1404\n",
      "Epoch 80/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m652s\u001b[0m 2s/step - accuracy: 0.9885 - loss: 0.0461 - val_accuracy: 0.8229 - val_loss: 1.3176\n",
      "Epoch 81/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m653s\u001b[0m 2s/step - accuracy: 0.9870 - loss: 0.0521 - val_accuracy: 0.8030 - val_loss: 1.2455\n",
      "Epoch 82/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m651s\u001b[0m 2s/step - accuracy: 0.9890 - loss: 0.0476 - val_accuracy: 0.8233 - val_loss: 1.3141\n",
      "Epoch 83/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m652s\u001b[0m 2s/step - accuracy: 0.9867 - loss: 0.0591 - val_accuracy: 0.8097 - val_loss: 1.0748\n",
      "Epoch 84/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m652s\u001b[0m 2s/step - accuracy: 0.9872 - loss: 0.0529 - val_accuracy: 0.8270 - val_loss: 0.9488\n",
      "Epoch 85/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m653s\u001b[0m 2s/step - accuracy: 0.9901 - loss: 0.0409 - val_accuracy: 0.7728 - val_loss: 1.3715\n",
      "Epoch 86/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m654s\u001b[0m 2s/step - accuracy: 0.9887 - loss: 0.0441 - val_accuracy: 0.8020 - val_loss: 1.2526\n",
      "Epoch 87/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m652s\u001b[0m 2s/step - accuracy: 0.9890 - loss: 0.0465 - val_accuracy: 0.7588 - val_loss: 1.5718\n",
      "Epoch 88/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m653s\u001b[0m 2s/step - accuracy: 0.9873 - loss: 0.0562 - val_accuracy: 0.8156 - val_loss: 1.3794\n",
      "Epoch 89/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m653s\u001b[0m 2s/step - accuracy: 0.9899 - loss: 0.0478 - val_accuracy: 0.8209 - val_loss: 1.0742\n",
      "Epoch 90/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m651s\u001b[0m 2s/step - accuracy: 0.9922 - loss: 0.0298 - val_accuracy: 0.8262 - val_loss: 1.4241\n",
      "Epoch 91/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m655s\u001b[0m 2s/step - accuracy: 0.9888 - loss: 0.0537 - val_accuracy: 0.8215 - val_loss: 1.1102\n",
      "Epoch 92/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m653s\u001b[0m 2s/step - accuracy: 0.9897 - loss: 0.0427 - val_accuracy: 0.8020 - val_loss: 1.2529\n",
      "Epoch 93/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m655s\u001b[0m 2s/step - accuracy: 0.9858 - loss: 0.0666 - val_accuracy: 0.8259 - val_loss: 1.4256\n",
      "Epoch 94/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m652s\u001b[0m 2s/step - accuracy: 0.9910 - loss: 0.0458 - val_accuracy: 0.8164 - val_loss: 1.0833\n",
      "Epoch 95/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m655s\u001b[0m 2s/step - accuracy: 0.9887 - loss: 0.0480 - val_accuracy: 0.8080 - val_loss: 1.0731\n",
      "Epoch 96/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m654s\u001b[0m 2s/step - accuracy: 0.9886 - loss: 0.0451 - val_accuracy: 0.8330 - val_loss: 1.1451\n",
      "Epoch 97/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m653s\u001b[0m 2s/step - accuracy: 0.9900 - loss: 0.0463 - val_accuracy: 0.8411 - val_loss: 1.1127\n",
      "Epoch 98/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m655s\u001b[0m 2s/step - accuracy: 0.9928 - loss: 0.0319 - val_accuracy: 0.8201 - val_loss: 1.2482\n",
      "Epoch 99/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m656s\u001b[0m 2s/step - accuracy: 0.9911 - loss: 0.0392 - val_accuracy: 0.8327 - val_loss: 1.1353\n",
      "Epoch 100/100\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m657s\u001b[0m 2s/step - accuracy: 0.9900 - loss: 0.0463 - val_accuracy: 0.8360 - val_loss: 1.1177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x29066549c10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, validation_data=val_ds, epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
